{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2StPehwLMat"
   },
   "source": [
    "# Tobig's 16기 3주차 Optimization 과제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKIX8PqcLMaw"
   },
   "source": [
    "# Gradient Descent 구현하기\n",
    "\n",
    "### 1)\"...\"표시되어 있는 빈 칸을 채워주세요\n",
    "### 2)강의내용과 코드에 대해 공부한 내용을 마크마운 또는 주석으로 설명해주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6DNHHXfLMax"
   },
   "source": [
    "## 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EP3O4xptLMay"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oByQ9wXHLMay"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>76000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  bias  experience  salary\n",
       "0      1     1         0.7   48000\n",
       "1      0     1         1.9   48000\n",
       "2      1     1         2.5   60000\n",
       "3      0     1         4.2   63000\n",
       "4      0     1         6.0   76000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('assignment_2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubOR3hWGLMaz"
   },
   "source": [
    "## Train Test 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IySSjlizLMaz"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "075EQI1bLMa0"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0], test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "O8Ht5u8kLMa1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 3), (50, 3), (150,), (50,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYmxND_xLMa2"
   },
   "source": [
    "## Scaling\n",
    "\n",
    "experience와 salary의 단위, 평균, 분산이 크게 차이나므로 scaler를 사용해 단위를 맞춰줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "UI0Xy0gHLMa3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.187893</td>\n",
       "      <td>-1.143335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.185555</td>\n",
       "      <td>0.043974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.310938</td>\n",
       "      <td>-0.351795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.629277</td>\n",
       "      <td>-1.341220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.308600</td>\n",
       "      <td>0.043974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias  experience    salary\n",
       "0     1    0.187893 -1.143335\n",
       "1     1    1.185555  0.043974\n",
       "2     1   -0.310938 -0.351795\n",
       "3     1   -1.629277 -1.341220\n",
       "4     1   -1.308600  0.043974"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "bias_train = X_train[\"bias\"]\n",
    "bias_train = bias_train.reset_index()[\"bias\"]\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_train[\"bias\"] = bias_train\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xD7L7RwZLMa3"
   },
   "source": [
    "이때 scaler는 X_train에 fit 해주시고, fit한 scaler를 X_test에 적용시켜줍니다.  \n",
    "똑같이 X_test에다 fit하면 안돼요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xBsUSCGGLMa3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.344231</td>\n",
       "      <td>-0.615642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.508570</td>\n",
       "      <td>0.307821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.310938</td>\n",
       "      <td>0.571667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>1.956862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.987923</td>\n",
       "      <td>-0.747565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias  experience    salary\n",
       "0     1   -1.344231 -0.615642\n",
       "1     1    0.508570  0.307821\n",
       "2     1   -0.310938  0.571667\n",
       "3     1    1.363709  1.956862\n",
       "4     1   -0.987923 -0.747565"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_test = X_test[\"bias\"]\n",
    "bias_test = bias_test.reset_index()[\"bias\"]\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "X_test[\"bias\"] = bias_test\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "m9sP3nzlLMa4"
   },
   "outputs": [],
   "source": [
    "# parameter 개수\n",
    "N = len(X_train.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qz7xz9dbLMa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8675472 , 0.85670259, 0.23900981])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 초기 parameter들을 임의로 설정해줍니다.\n",
    "parameters = np.array([random.random() for i in range(N)])\n",
    "random_parameters = parameters.copy()\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QINz-EAKLMa4"
   },
   "source": [
    "### * LaTeX   \n",
    "\n",
    "Jupyter Notebook은 LaTeX 문법으로 수식 입력을 지원하고 있습니다.  \n",
    "LaTeX문법으로 아래의 수식을 완성해주세요  \n",
    "http://triki.net/apps/3466  \n",
    "https://jjycjnmath.tistory.com/117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2DsTfXuLMa5"
   },
   "source": [
    "## Dot product\n",
    "## $z = X_i \\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2y05lS6xLMa5"
   },
   "outputs": [],
   "source": [
    "def dot_product(X, parameters):\n",
    "    z = 0\n",
    "    for i in range(len(parameters)):\n",
    "        z += X[i] * parameters[i]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOGPEhtOLMa5"
   },
   "source": [
    "## Logistic Function\n",
    "\n",
    "## $p = \\frac{1}{1 + e^{-x_{i}\\theta}} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2awM57u5LMa5"
   },
   "outputs": [],
   "source": [
    "def logistic(X, parameters):\n",
    "    z = dot_product(X, parameters)\n",
    "    p = 1 / (1 + np.exp(-z))   \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "WVaZEwrdLMa5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8691797532005683"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic(X_train.iloc[1], parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6cXHl8bLMa6"
   },
   "source": [
    "## Object function\n",
    "\n",
    "Object Function : 목적함수는 Gradient Descent를 통해 최적화 하고자 하는 함수입니다.  \n",
    "<br>\n",
    "선형 회귀의 목적함수\n",
    "## $l(\\theta) = \\frac{1}{2}\\Sigma(y_i - \\theta^{T}X_i)^2$  \n",
    "참고) $\\hat{y_i} = \\theta^{T}X_i$\n",
    "  \n",
    "로지스틱 회귀의 목적함수를 작성해주세요  \n",
    "(선형 회귀의 목적함수처럼 강의에 나온대로 작성해주세요. 평균을 고려하는 것은 뒤에 코드에서 수행합니다)\n",
    "## $l(p) =- \\Sigma(y_{i}\\log p(X_{i}) + (1 - y_{i}) \\log(1 - p(X_{i}))) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "FnGRAur3LMa6"
   },
   "outputs": [],
   "source": [
    "def minus_log_cross_entropy_i(X, y, parameters):\n",
    "    p = logistic(X, parameters)\n",
    "    loss = -(y * np.log(p) + (1-y) * np.log(1-p))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "C922eXYyLMa6"
   },
   "outputs": [],
   "source": [
    "def mse_i(X, y, parameters):\n",
    "    y_hat = np.dot(X, parameters.T)\n",
    "    loss = ((y-y_hat)**2) / 2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_i(X, y, parameters):\n",
    "    y_hat = np.dot(X, parameters.T)\n",
    "    loss = ((y - y_hat)**2) / 2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0j-MhGkyLMa6"
   },
   "outputs": [],
   "source": [
    "def batch_loss(X_set, y_set, parameters, loss_function, n): #n:현재 배치의 데이터 수\n",
    "    loss = 0\n",
    "    for i in range(X_set.shape[0]):\n",
    "        X = X_set.iloc[i,:]\n",
    "        y = y_set.iloc[i]\n",
    "        loss += loss_function(X, y, parameters)\n",
    "    loss = loss / n #loss 평균값으로 계산\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "uSkPS5olLMa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.283259620095605"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_loss(X_test, y_test, parameters, minus_log_cross_entropy_i, len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACLi9vCyLMa7"
   },
   "source": [
    "## Gradient\n",
    "위의 선형회귀의 목적함수 $l(\\theta)$와 로지스틱회귀의 목적함수 $l(p)$의 gradient를 작성해주세요  \n",
    "(위의 목적함수를 참고해서 작성해주세요 = 평균을 고려하는 것은 뒤에 코드에서 수행합니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caMA-f00LMa7"
   },
   "source": [
    "## ${\\partial\\over{\\partial \\theta_j}}l(\\theta)=$ $ -\\Sigma(y_{i} - \\theta^{T}X_{i})X_{ij} $\n",
    "## ${\\partial\\over{\\partial \\theta_j}}l(p)=$ $ -\\Sigma(y_{i} - p_{i})X_{ij} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_ij(X, y, parameters, j, model):\n",
    "    if model == 'linear':\n",
    "        y_hat = np.dot(X, parameters.T)\n",
    "        gradient = (y-y_hat) * X[j]\n",
    "    else:\n",
    "        p = logistic(X, parameters)\n",
    "        gradient = -((y-p) * X[j])\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "XXBe6q8gLMa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0600654591087463"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gradient_ij(X_train.iloc[0,:], y_train.iloc[0], parameters, 1, 'logistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTfzKh_nLMa7"
   },
   "source": [
    "## Batch Gradient\n",
    "하나의 배치 (X_set, y_set)에 대해 기울기를 구하는 코드를 작성해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Qby2_X1vLMa7"
   },
   "outputs": [],
   "source": [
    "def batch_gradient(X_set, y_set, parameters, model):\n",
    "    gradients = [0 for _ in range(len(parameters))]\n",
    "    \n",
    "    for i in range(len(X_set)):\n",
    "        X = X_set.iloc[i,:]\n",
    "        y = y_set.iloc[i]\n",
    "        for j in range(len(parameters)):\n",
    "            gradients[j] += get_gradient_ij(X, y, parameters, j, model)\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "rHxBS5RnLMa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[57.88774294628386, 10.86305635349856, 38.13427293360216]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients1 = batch_gradient(X_train, y_train, parameters, 'logistic')\n",
    "gradients1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQnlDboALMa8"
   },
   "source": [
    "## mini-batch\n",
    "인덱스로 미니 배치 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "LgnfT6eHLMa8"
   },
   "outputs": [],
   "source": [
    "def batch_idx(X_train, batch_size):\n",
    "    N = len(X_train)\n",
    "    nb = (N // batch_size)+1 #number of batch\n",
    "    idx = np.array([i for i in range(N)])\n",
    "    idx_list = [idx[i*batch_size:(i+1)*batch_size] for i in range(nb) if len(idx[i*batch_size:(i+1)*batch_size]) != 0]\n",
    "    return idx_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9S9fk1UTLMa8"
   },
   "source": [
    "batch_idx 함수에 대한 설명을 batch_size와 함께 간략하게 작성해주세요  \n",
    "### 설명: \n",
    "Mini Batch Gradient Descent는 한습 한 번에 데이터셋의 일부에 대해서만 기울기를 계산하기 때문에 한 번 학습할 때 batch_size만큼의 임의의 데이터셋을 사용한다. batch_idx 함수는 이 때 사용된 데이터가 무엇인지 나타내기 위해 인덱스값을 반환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pMuZbkQLMa8"
   },
   "source": [
    "## Update Parameters\n",
    "기울기를 갱신하는 코드를 작성해주세요  \n",
    "(loss와 마찬가지로 기울기를 갱신할 때 배치 사이즈를 고려해 평균으로 갱신해주세요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "loeL51rPLMa8"
   },
   "outputs": [],
   "source": [
    "def step(parameters, gradients, learning_rate, n): #n:현재 배치의 데이터 수\n",
    "    for i in range(len(parameters)):\n",
    "        gradients[i] *= learning_rate / n\n",
    "    \n",
    "    parameters -= gradients\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "NLB2dUVTLMa8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86368802, 0.85597839, 0.23646753])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step(parameters, gradients1, 0.01, len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RX8RJFd_LMa9"
   },
   "source": [
    "## Gradient Descent\n",
    "위에서 작성한 함수들을 조합해서 경사하강법 함수를 완성해주세요\n",
    "\n",
    "- learning_rate: 학습률  \n",
    "- tolerance: Step이 너무 작아서 더 이상의 학습이 무의미할 때 학습을 멈추는 조건  \n",
    "- batch: 기울기를 1번 갱신할 때 사용하는 데이터셋  \n",
    "- epoch: 현재 학습 횟수\n",
    "- num_epoch: 전체 데이터를 학습하는 총 횟수\n",
    "<br>\n",
    "\n",
    "BGD(Batch Gradient Descent): 학습 한 번에 모든 데이터셋에 대해 기울기를 계산 \n",
    "SGD(Stochastic Gradient Descent): 학습 한 번에 임의의 데이터 하나에 대해서만 기울기를 계산\n",
    "MGD(Mini Batch Gradient Descent): 학습 한 번에 데이터셋의 일부에 대해서만 기울기를 계산\n",
    "<br>\n",
    "batch_size에 따른 경사하강법의 종류를 적어주세요  \n",
    "batch_size=1 -> SGD <br>\n",
    "batch_size=k -> MGD <br>\n",
    "batch_size=whole -> BGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ZGbnVHbbLMa9"
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X_train, y_train, learning_rate = 0.1, num_epoch = 1000, tolerance = 0.00001, model = 'logistic', batch_size = 16):\n",
    "    stopper = False\n",
    "    \n",
    "    N = len(X_train.iloc[0])\n",
    "    parameters = np.random.rand(N)\n",
    "    \n",
    "    loss_function = minus_log_cross_entropy_i if model == 'logistic' else mse_i\n",
    "    loss = 999\n",
    "    batch_idx_list = batch_idx(X_train, batch_size)\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        if stopper:\n",
    "            break\n",
    "        for idx in batch_idx_list:\n",
    "            X_batch = X_train.iloc[idx,]\n",
    "            y_batch = y_train.iloc[idx]\n",
    "            gradients = batch_gradient(X_batch, y_batch, parameters, model)\n",
    "            parameters = step(parameters, gradients, learning_rate, len(X_batch))\n",
    "            new_loss = batch_loss(X_batch, y_batch, parameters, loss_function, len(X_batch))\n",
    "            \n",
    "            #중단 조건\n",
    "            if abs(new_loss - loss) < tolerance:\n",
    "                stopper = True\n",
    "                break\n",
    "            loss = new_loss\n",
    "        \n",
    "        #100epoch마다 학습 상태 출력\n",
    "        if epoch%100 == 0: #출력이 길게 나오면 check point를 수정해도 됩니다.\n",
    "            print(f\"epoch: {epoch}  loss: {new_loss}  params: {parameters}  gradients: {gradients}\")\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3CTtc3eiLMa9"
   },
   "source": [
    "## Implement\n",
    "경사하강법 함수를 이용해 최적의 모수 찾아보세요. 학습을 진행할 때, Hyper Parameter를 바꿔가면서 학습시켜보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnUpYC7_LMa9"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.8763102129550872  params: [0.52816251 0.24192482 0.32233487]  gradients: [0.03480189852845223, -0.0011980487378194025, 0.020698200925397422]\n",
      "epoch: 100  loss: 0.45845026488401924  params: [-0.81084304  0.83453784 -0.75507558]  gradients: [0.00395325460391564, -0.00641505195703935, 0.006590525957042062]\n",
      "epoch: 200  loss: 0.3943390917634493  params: [-1.02988125  1.37631617 -1.29300497]  gradients: [0.0013238160228640752, -0.004560732759830591, 0.004463362309964241]\n",
      "epoch: 300  loss: 0.3628535076827775  params: [-1.13590957  1.76970893 -1.67642553]  gradients: [0.0008929594947545248, -0.0034127806452985566, 0.003313380780235591]\n",
      "epoch: 400  loss: 0.3444753192304073  params: [-1.21590175  2.07178829 -1.96877048]  gradients: [0.0007241271311171617, -0.0026864176920669363, 0.002591494185718843]\n",
      "epoch: 500  loss: 0.33270793835836815  params: [-1.28235737  2.31400333 -2.20179392]  gradients: [0.0006116138995813922, -0.002191683560462432, 0.00210286424886729]\n",
      "epoch: 600  loss: 0.3246901073220822  params: [-1.33896496  2.51423268 -2.39347101]  gradients: [0.000524777994273484, -0.0018343253929991067, 0.0017520422382987825]\n",
      "epoch: 700  loss: 0.3189783172980236  params: [-1.38780763  2.68344926 -2.5547841 ]  gradients: [0.0004552264634971453, -0.0015644661352936249, 0.0014885631720199636]\n",
      "epoch: 800  loss: 0.3147714502902137  params: [-1.43037499  2.82884195 -2.69289271]  gradients: [0.0003985512254993882, -0.0013536472629449238, 0.0012837347280850277]\n",
      "epoch: 900  loss: 0.31159205381294763  params: [-1.46779371  2.95537254 -2.81271514]  gradients: [0.00035172952086438624, -0.0011845377320457012, 0.0011201529712391244]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.50061979,  3.06556483, -2.91678767])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_param_bgd = gradient_descent(X_train, y_train, batch_size = X_train.shape[0])\n",
    "new_param_bgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "x0H5tnauLMa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.27458984814695325  params: [-0.89156966  1.09101057 -1.21406016]  gradients: [0.024832564958143233, 0.013513905601777471, 0.017471962799437885]\n",
      "epoch: 100  loss: 0.07736671409386778  params: [-1.93032568  4.1750195  -4.06769113]  gradients: [0.007538543356787982, 0.0041024825051401695, 0.005304049312415353]\n",
      "epoch: 200  loss: 0.07736266552157411  params: [-1.9303681   4.1751431  -4.06780374]  gradients: [0.0075381595218080265, 0.004102273621776952, 0.005303779249677082]\n",
      "epoch: 300  loss: 0.07736266518361716  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489767122, 0.004102273604340261, 0.005303779227133398]\n",
      "epoch: 400  loss: 0.07736266518359017  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 500  loss: 0.07736266518359017  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 600  loss: 0.07736266518359017  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 700  loss: 0.07736266518359017  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 800  loss: 0.07736266518359017  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n",
      "epoch: 900  loss: 0.07736266518359017  params: [-1.9303681   4.17514311 -4.06780375]  gradients: [0.007538159489764571, 0.004102273604338872, 0.005303779227131603]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.9303681 ,  4.17514311, -4.06780375])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_param_sgd = gradient_descent(X_train, y_train, batch_size = 1)\n",
    "new_param_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "-LS6o3aeLMa-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.8337476594154678  params: [-0.24689191  0.20337169  0.34337541]  gradients: [0.04109761910790211, 0.039110848285012344, 0.05408486996172611]\n",
      "epoch: 100  loss: 0.18307120940427898  params: [-1.70921761  3.67186596 -3.51852114]  gradients: [0.008221868503711172, 0.012106124273992777, 0.014576121991512658]\n",
      "epoch: 200  loss: 0.16719005886418578  params: [-1.84519583  4.10573674 -3.92127877]  gradients: [0.008040559006781588, 0.011959501138841403, 0.01382979059915093]\n",
      "epoch: 300  loss: 0.16337175546577284  params: [-1.88222857  4.22329735 -4.02984313]  gradients: [0.008005863453358044, 0.011928360108396655, 0.0136530055577422]\n",
      "epoch: 400  loss: 0.16226168884912814  params: [-1.89336778  4.25861644 -4.06241387]  gradients: [0.007996451988560773, 0.011919632279585302, 0.013601822534142423]\n",
      "epoch: 500  loss: 0.16192223759108548  params: [-1.89680921  4.26952438 -4.0724688 ]  gradients: [0.00799363532786596, 0.011916993249114619, 0.01358619065611887]\n",
      "epoch: 600  loss: 0.16181685625578343  params: [-1.89788099  4.27292111 -4.07559949]  gradients: [0.007992766762323644, 0.011916176836284521, 0.013581339676849873]\n",
      "epoch: 700  loss: 0.16178398836595248  params: [-1.8982156   4.27398154 -4.07657683]  gradients: [0.007992496429339937, 0.01191592247949843, 0.013579826864018658]\n",
      "epoch: 800  loss: 0.16177372217796954  params: [-1.89832015  4.27431286 -4.07688219]  gradients: [0.00799241204700899, 0.011915843059029511, 0.013579354359196468]\n",
      "epoch: 900  loss: 0.1617705141139903  params: [-1.89835282  4.2744164  -4.07697762]  gradients: [0.00799238568392084, 0.011915818243707181, 0.01357920670868795]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.89836298,  4.27444859, -4.07700728])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_param_mgd = gradient_descent(X_train, y_train, batch_size = 8)\n",
    "new_param_mgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0oCaZ0tLMa-"
   },
   "source": [
    "### Predict Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "syJE3oiNLMa-"
   },
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "for i in range(len(y_test)):\n",
    "    p = logistic(X_test.iloc[i,:], new_param_sgd)\n",
    "    if p> 0.5 :\n",
    "        y_predict.append(1)\n",
    "    else :\n",
    "        y_predict.append(0)\n",
    "y_predict_random = []\n",
    "for i in range(len(y_test)):\n",
    "    p = logistic(X_test.iloc[i,:], random_parameters)\n",
    "    if p> 0.5 :\n",
    "        y_predict_random.append(1)\n",
    "    else :\n",
    "        y_predict_random.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZKpFItfLMa-"
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "W4E1PgX5LMa-"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38,  2],\n",
       "       [ 4,  6]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BGD\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38,  2],\n",
       "       [ 1,  9]], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SGD\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "-veTwxu4LMa-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38,  2],\n",
       "       [ 1,  9]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MGD\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BGD accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp+tn) / (tp+fn+fp+tn)\n",
    "print(\"BGD accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp+tn) / (tp+fn+fp+tn)\n",
    "print(\"SGD accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MGD accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp+tn) / (tp+fn+fp+tn)\n",
    "print(\"MGD accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIgqa85aLMa_"
   },
   "source": [
    "## Linear regression\n",
    "### $y = 0.5 + 2.7x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYeIg9QNLMa_"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "nv8-yhszLMa_"
   },
   "outputs": [],
   "source": [
    "raw_X = np.random.rand(150)\n",
    "y = 2.7*raw_X + 0.5 + np.random.randn(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "07XtxLGWLMa_"
   },
   "outputs": [],
   "source": [
    "tmp = np.array([1 for _ in range(150)])\n",
    "X = np.vstack((tmp, raw_X)).T\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oENC02TLMa_"
   },
   "source": [
    "### Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "fu578YrKLMa_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61342752, 2.27238257])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정규방정식\n",
    "theta = np.linalg.inv(np.dot(X.T,X)).dot(X.T).dot(y)\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "M74iqj4WLMa_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  loss: 0.39332275073051554  params: [0.99120348 1.04796538]  gradients: [-0.0517902549605577, -0.0353518207403942]\n",
      "epoch: 100  loss: 0.22212365801253833  params: [0.63796111 2.30426226]  gradients: [-0.022043948485011736, -0.01491490661418284]\n",
      "epoch: 200  loss: 0.22200651275325947  params: [0.63541535 2.30876503]  gradients: [-0.02208337586682535, -0.014913021281871422]\n",
      "epoch: 300  loss: 0.2220060358042241  params: [0.63540494 2.30878345]  gradients: [-0.02208353713540278, -0.014913013570356067]\n",
      "epoch: 400  loss: 0.22200603385341144  params: [0.63540489 2.30878353]  gradients: [-0.02208353779503459, -0.014913013538813906]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.63540489, 2.30878353])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#경사하강법\n",
    "new_param = gradient_descent(X, y, model='linear', num_epoch=500)\n",
    "new_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "Ii3zBOwSLMa_"
   },
   "outputs": [],
   "source": [
    "y_hat_NE = theta.dot(X.T)\n",
    "y_hat_GD = new_param.dot(X.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCVynFSPLMbA"
   },
   "source": [
    "### Visualization\n",
    "시각화를 통해 정규방정식과 경사하강법을 통한 선형회귀를 비교해보세요  \n",
    "(밑의 코드를 실행만 시키면 됩니다. 추가 코드 x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "UoEACrbYLMbA"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X.iloc[:,1], y, '.k') #산점도\n",
    "plt.plot(X.iloc[:,1], y_hat_NE, '-b', label = 'NE') #정규방정식\n",
    "plt.plot(X.iloc[:,1], y_hat_GD, '-r', label = 'GD') #경사하강법\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijgIcAdGLMbA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "wk3_optimization_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
