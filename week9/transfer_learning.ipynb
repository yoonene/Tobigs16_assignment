{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week09_transfer_learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrVFrYpPtHRv"
      },
      "source": [
        "# 투빅스 16기 9주차 과제 Transfer Learning\n",
        "\n",
        "데이터: 7개의 클래스로 분류되어 있는 명화 이미지<br>\n",
        "dog, elephant, giraffe, guitar, horse, house, person"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNc8EkRys6A4",
        "outputId": "b6a68d1b-96da-4dea-f48d-ec97a8b906d9"
      },
      "source": [
        "# gdrive에 mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/Mydrive', force_remount = True)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/Mydrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRUUTHl0tLoh"
      },
      "source": [
        "# 경로 설정\n",
        "import os\n",
        "os.chdir('/content/Mydrive/MyDrive/Tobigs/정규세션_CNN심화')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAvG4EYb2MMX"
      },
      "source": [
        "# Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h8QPKNk2Ysw"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Data\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder \n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Pytorch --> CNN\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchsummary import summary "
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wN9eQxFvc5H",
        "outputId": "fee815d9-23aa-464a-90cd-1320d50b6d47"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  DEVICE = torch.device('cuda')\n",
        "else:\n",
        "  DEVICE = torch.device('cpu')\n",
        "print(DEVICE)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb-i9tqi2GS-"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtrNo7uDtM_B"
      },
      "source": [
        "import shutil\n",
        "\n",
        "original_dataset_dir = './data'                   # 기존의 데이터\n",
        "classes_list = os.listdir(original_dataset_dir) \n",
        " \n",
        "base_dir = './splitted'                           # train-validation-test 나누기\n",
        "os.mkdir(base_dir)\n",
        " \n",
        "train_dir = os.path.join(base_dir, 'train') \n",
        "os.mkdir(train_dir)\n",
        "validation_dir = os.path.join(base_dir, 'val')\n",
        "os.mkdir(validation_dir)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "for cls in classes_list:     \n",
        "    os.mkdir(os.path.join(train_dir, cls))\n",
        "    os.mkdir(os.path.join(validation_dir, cls))\n",
        "    os.mkdir(os.path.join(test_dir, cls))"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2hCPiFnu1mY",
        "outputId": "449389a4-2f0e-4627-daef-539926cc06df"
      },
      "source": [
        "## 데이터 분할 후 클래스별 데이터 수 확인\n",
        "\n",
        "import math\n",
        " \n",
        "for cls in classes_list:\n",
        "    path = os.path.join(original_dataset_dir, cls)\n",
        "    fnames = os.listdir(path)\n",
        " \n",
        "    train_size = math.floor(len(fnames) * 0.6)\n",
        "    validation_size = math.floor(len(fnames) * 0.2)\n",
        "    test_size = math.floor(len(fnames) * 0.2)\n",
        "    \n",
        "    train_fnames = fnames[:train_size]\n",
        "    print(\"Train size(\",cls,\"): \", len(train_fnames))\n",
        "    for fname in train_fnames:\n",
        "        src = os.path.join(path, fname)\n",
        "        dst = os.path.join(os.path.join(train_dir, cls), fname)\n",
        "        shutil.copyfile(src, dst)\n",
        "        \n",
        "    validation_fnames = fnames[train_size:(validation_size + train_size)]\n",
        "    print(\"Validation size(\",cls,\"): \", len(validation_fnames))\n",
        "    for fname in validation_fnames:\n",
        "        src = os.path.join(path, fname)\n",
        "        dst = os.path.join(os.path.join(validation_dir, cls), fname)\n",
        "        shutil.copyfile(src, dst)\n",
        "        \n",
        "    test_fnames = fnames[(train_size+validation_size):(validation_size + train_size +test_size)]\n",
        "\n",
        "    print(\"Test size(\",cls,\"): \", len(test_fnames))\n",
        "    for fname in test_fnames:\n",
        "        src = os.path.join(path, fname)\n",
        "        dst = os.path.join(os.path.join(test_dir, cls), fname)\n",
        "        shutil.copyfile(src, dst)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size( elephant ):  123\n",
            "Validation size( elephant ):  41\n",
            "Test size( elephant ):  41\n",
            "Train size( house ):  147\n",
            "Validation size( house ):  49\n",
            "Test size( house ):  49\n",
            "Train size( guitar ):  80\n",
            "Validation size( guitar ):  26\n",
            "Test size( guitar ):  26\n",
            "Train size( horse ):  90\n",
            "Validation size( horse ):  30\n",
            "Test size( horse ):  30\n",
            "Train size( giraffe ):  141\n",
            "Validation size( giraffe ):  47\n",
            "Test size( giraffe ):  47\n",
            "Train size( person ):  239\n",
            "Validation size( person ):  79\n",
            "Test size( person ):  79\n",
            "Train size( dog ):  197\n",
            "Validation size( dog ):  65\n",
            "Test size( dog ):  65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO6tX_EKviE5"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCH = 30"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5xJCU4dvjpb"
      },
      "source": [
        " transform_base = transforms.Compose([transforms.Resize((256,256)),transforms.ToTensor()]) # AlexNet의 input size에 맞춤 (64x64는 너무 작음)\n",
        "train_dataset = ImageFolder(root='./splitted/train', transform=transform_base) \n",
        "val_dataset = ImageFolder(root='./splitted/val', transform=transform_base)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "635CjT5Zvjnl",
        "outputId": "0f0787fb-a677-4269-da49-ff4f540805d3"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset,batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SEuqzjKvMIk"
      },
      "source": [
        "# Baseline Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oM1HaCCM8fvH",
        "outputId": "47e89c8d-5474-47de-8193-84ea90a54de2"
      },
      "source": [
        "class Net(nn.Module): # 모델 설계\n",
        "    def __init__(self, n_classes = 7):   \n",
        "        ####  모델을 설계해 주세요 ####\n",
        "        # AlexNet 구현\n",
        "        super(Net, self).__init__()\n",
        "        self.convnet = nn.Sequential(\n",
        "            # Input Channel (RGB: 3)\n",
        "            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, padding=0, stride=4), # 227 -> 55\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(size=5, k=2),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), # 55 -> 27\n",
        "            \n",
        "            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, padding=2, stride=1), # 27 -> 27\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(size=5, k=2),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), # 27 -> 13\n",
        "            \n",
        "            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(size=5, k=2),\n",
        "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(size=5, k=2),\n",
        "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1, stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(size=5, k=2),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), # 13 -> 6\n",
        "        )\n",
        "\n",
        "        self.fclayer = nn.Sequential(\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, n_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):   \n",
        "        x = self.convnet(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        out = self.fclayer(x)\n",
        "        return F.log_softmax(out) # softmax 통해 최종 output 계산\n",
        "\n",
        "\n",
        "# print model summary\n",
        "model_base = Net().to(DEVICE)\n",
        "summary(model_base, (3, 227, 227)) "
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 55, 55]          34,944\n",
            "              ReLU-2           [-1, 96, 55, 55]               0\n",
            " LocalResponseNorm-3           [-1, 96, 55, 55]               0\n",
            "         MaxPool2d-4           [-1, 96, 27, 27]               0\n",
            "            Conv2d-5          [-1, 256, 27, 27]         614,656\n",
            "              ReLU-6          [-1, 256, 27, 27]               0\n",
            " LocalResponseNorm-7          [-1, 256, 27, 27]               0\n",
            "         MaxPool2d-8          [-1, 256, 13, 13]               0\n",
            "            Conv2d-9          [-1, 384, 13, 13]         885,120\n",
            "             ReLU-10          [-1, 384, 13, 13]               0\n",
            "LocalResponseNorm-11          [-1, 384, 13, 13]               0\n",
            "           Conv2d-12          [-1, 384, 13, 13]       1,327,488\n",
            "             ReLU-13          [-1, 384, 13, 13]               0\n",
            "LocalResponseNorm-14          [-1, 384, 13, 13]               0\n",
            "           Conv2d-15          [-1, 256, 13, 13]         884,992\n",
            "             ReLU-16          [-1, 256, 13, 13]               0\n",
            "LocalResponseNorm-17          [-1, 256, 13, 13]               0\n",
            "        MaxPool2d-18            [-1, 256, 6, 6]               0\n",
            "           Linear-19                 [-1, 4096]      37,752,832\n",
            "             ReLU-20                 [-1, 4096]               0\n",
            "          Dropout-21                 [-1, 4096]               0\n",
            "           Linear-22                 [-1, 4096]      16,781,312\n",
            "             ReLU-23                 [-1, 4096]               0\n",
            "          Dropout-24                 [-1, 4096]               0\n",
            "           Linear-25                    [-1, 7]          28,679\n",
            "================================================================\n",
            "Total params: 58,310,023\n",
            "Trainable params: 58,310,023\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 16.00\n",
            "Params size (MB): 222.44\n",
            "Estimated Total Size (MB): 239.03\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94vD1JHB2Afb"
      },
      "source": [
        "# Optimizer, Loss function 은 편하신 대로 변경하시면 됩니다 :) \n",
        "\n",
        "# optimizer = optim.SGD(model_base.parameters(), lr=0.001) \n",
        "optimizer = optim.Adam(model_base.parameters(), lr=0.001) \n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n3hmF3R4NTs"
      },
      "source": [
        "**Train** Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZyDWaeO3bNh"
      },
      "source": [
        "def train(model, train_loader, optimizer):\n",
        "    model.train()                         # 모델 train 상태로\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)   # data, target 값 DEVICE에 할당\n",
        "        optimizer.zero_grad()                                             # optimizer gradient 값 초기화\n",
        "        output = model(data)                                             # 할당된 데이터로 output 계산\n",
        "        loss = criterion(output, target)                                           # Cross Entropy Loss 사용해 loss 계산\n",
        "        loss.backward()                                           # 계산된 loss back propagation\n",
        "        optimizer.step()                                    # parameter update"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTb_xWhi40P-"
      },
      "source": [
        "Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R58K5n6q4PnI"
      },
      "source": [
        "def evaluate(model, test_loader):\n",
        "    model.eval()      # 모델 평가 상태로\n",
        "    test_loss = 0     # test_loss 초기화\n",
        "    correct = 0       # 맞게 예측한 0 값으로 초기화\n",
        "    \n",
        "    with torch.no_grad(): \n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(DEVICE), target.to(DEVICE)     # data, target DEVICE에 할당\n",
        "            output = model(data)                                                 # output 계산\n",
        "            test_loss += criterion(output, target).item()         # loss 계산(총 loss 에 더해주기)\n",
        "            pred = output.max(1, keepdim=True)[1]                 # 계산된 벡터값 중 가장 큰 값 가지는 class 예측\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item() # 맞게 예측한 값 세기\n",
        "   \n",
        "    test_loss /= len(test_loader.dataset)                         # 평균 loss\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)     # test(validation) 데이터 정확도\n",
        "    return test_loss, test_accuracy  "
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdR9vkET417H"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHMOT3BE9MTe",
        "outputId": "9c1e65b8-cedb-461f-9e5a-6c471391ee3e"
      },
      "source": [
        "import time\n",
        "import copy\n",
        "# Batch 128, 0.001\n",
        "def train_baseline(model ,train_loader, val_loader, optimizer, num_epochs = 30):\n",
        "    best_acc = 0.0  # beset accuracy 초기화\n",
        "    best_model_wts = copy.deepcopy(model.state_dict()) \n",
        " \n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        since = time.time()                                     # 학습 시간 계산\n",
        "        train(model, train_loader, optimizer)                   # train 데이터로 학습\n",
        "        train_loss, train_acc = evaluate(model, train_loader)   # train_loss, train_acc 계산\n",
        "        val_loss, val_acc = evaluate(model, val_loader)         # valid_loss, valid_acc 계산\n",
        "        \n",
        "        if val_acc>best_acc:  # update best accuracy\n",
        "            best_acc = val_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        \n",
        "        time_elapsed = time.time() - since # 학습 시간 출력\n",
        "        print('-------------- epoch {} ----------------'.format(epoch))\n",
        "        print('train Loss: {:.4f}, Accuracy: {:.2f}%'.format(train_loss, train_acc))   \n",
        "        print('val Loss: {:.4f}, Accuracy: {:.2f}%'.format(val_loss, val_acc))\n",
        "        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) \n",
        "\n",
        "    model.load_state_dict(best_model_wts)  \n",
        "    return model\n",
        "\n",
        "base = train_baseline(model_base ,train_loader, val_loader, optimizer)  \t# 모델 학습시키기\n",
        "torch.save(base,'AlexNet.pt')                                             # 모델 저장"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------- epoch 1 ----------------\n",
            "train Loss: 0.0296, Accuracy: 23.50%\n",
            "val Loss: 0.0338, Accuracy: 23.44%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 2 ----------------\n",
            "train Loss: 0.0298, Accuracy: 19.37%\n",
            "val Loss: 0.0338, Accuracy: 19.29%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 3 ----------------\n",
            "train Loss: 0.0299, Accuracy: 20.45%\n",
            "val Loss: 0.0340, Accuracy: 19.29%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 4 ----------------\n",
            "train Loss: 0.0293, Accuracy: 24.68%\n",
            "val Loss: 0.0334, Accuracy: 24.33%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 5 ----------------\n",
            "train Loss: 0.0300, Accuracy: 23.50%\n",
            "val Loss: 0.0344, Accuracy: 23.44%\n",
            "Completed in 0m 14s\n",
            "-------------- epoch 6 ----------------\n",
            "train Loss: 0.0286, Accuracy: 26.16%\n",
            "val Loss: 0.0335, Accuracy: 21.66%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 7 ----------------\n",
            "train Loss: 0.0282, Accuracy: 27.83%\n",
            "val Loss: 0.0325, Accuracy: 29.08%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 8 ----------------\n",
            "train Loss: 0.0284, Accuracy: 25.07%\n",
            "val Loss: 0.0328, Accuracy: 24.33%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 9 ----------------\n",
            "train Loss: 0.0284, Accuracy: 28.42%\n",
            "val Loss: 0.0330, Accuracy: 25.22%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 10 ----------------\n",
            "train Loss: 0.0278, Accuracy: 30.09%\n",
            "val Loss: 0.0321, Accuracy: 29.38%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 11 ----------------\n",
            "train Loss: 0.0278, Accuracy: 31.17%\n",
            "val Loss: 0.0324, Accuracy: 26.71%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 12 ----------------\n",
            "train Loss: 0.0279, Accuracy: 28.12%\n",
            "val Loss: 0.0322, Accuracy: 31.75%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 13 ----------------\n",
            "train Loss: 0.0269, Accuracy: 30.58%\n",
            "val Loss: 0.0318, Accuracy: 29.08%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 14 ----------------\n",
            "train Loss: 0.0278, Accuracy: 26.65%\n",
            "val Loss: 0.0323, Accuracy: 28.19%\n",
            "Completed in 0m 14s\n",
            "-------------- epoch 15 ----------------\n",
            "train Loss: 0.0280, Accuracy: 27.83%\n",
            "val Loss: 0.0336, Accuracy: 21.36%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 16 ----------------\n",
            "train Loss: 0.0265, Accuracy: 32.74%\n",
            "val Loss: 0.0325, Accuracy: 28.19%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 17 ----------------\n",
            "train Loss: 0.0264, Accuracy: 35.69%\n",
            "val Loss: 0.0316, Accuracy: 27.30%\n",
            "Completed in 0m 14s\n",
            "-------------- epoch 18 ----------------\n",
            "train Loss: 0.0264, Accuracy: 36.38%\n",
            "val Loss: 0.0319, Accuracy: 26.71%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 19 ----------------\n",
            "train Loss: 0.0255, Accuracy: 36.97%\n",
            "val Loss: 0.0326, Accuracy: 26.71%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 20 ----------------\n",
            "train Loss: 0.0250, Accuracy: 39.53%\n",
            "val Loss: 0.0327, Accuracy: 30.56%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 21 ----------------\n",
            "train Loss: 0.0244, Accuracy: 39.33%\n",
            "val Loss: 0.0320, Accuracy: 29.97%\n",
            "Completed in 0m 14s\n",
            "-------------- epoch 22 ----------------\n",
            "train Loss: 0.0237, Accuracy: 44.84%\n",
            "val Loss: 0.0316, Accuracy: 30.86%\n",
            "Completed in 0m 14s\n",
            "-------------- epoch 23 ----------------\n",
            "train Loss: 0.0230, Accuracy: 44.84%\n",
            "val Loss: 0.0330, Accuracy: 26.41%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 24 ----------------\n",
            "train Loss: 0.0262, Accuracy: 49.95%\n",
            "val Loss: 0.0379, Accuracy: 30.86%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 25 ----------------\n",
            "train Loss: 0.0229, Accuracy: 50.74%\n",
            "val Loss: 0.0356, Accuracy: 30.56%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 26 ----------------\n",
            "train Loss: 0.0203, Accuracy: 53.29%\n",
            "val Loss: 0.0335, Accuracy: 34.12%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 27 ----------------\n",
            "train Loss: 0.0189, Accuracy: 55.85%\n",
            "val Loss: 0.0326, Accuracy: 35.01%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 28 ----------------\n",
            "train Loss: 0.0172, Accuracy: 62.44%\n",
            "val Loss: 0.0374, Accuracy: 34.12%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 29 ----------------\n",
            "train Loss: 0.0165, Accuracy: 62.24%\n",
            "val Loss: 0.0374, Accuracy: 34.72%\n",
            "Completed in 0m 13s\n",
            "-------------- epoch 30 ----------------\n",
            "train Loss: 0.0169, Accuracy: 59.19%\n",
            "val Loss: 0.0371, Accuracy: 32.34%\n",
            "Completed in 0m 13s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE_SnE_a6kCv"
      },
      "source": [
        "## Test Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2teaHIW16948",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39af67b3-d2c7-41ce-c1ae-68da8fa993ae"
      },
      "source": [
        "# Test Data Classification 하기\n",
        "transform_base = transforms.Compose([transforms.ToTensor()]) \n",
        "test_base = ImageFolder(root='./splitted/test',transform=transform_base)  \n",
        "test_loader_base = torch.utils.data.DataLoader(test_base, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5EFgn0jT840"
      },
      "source": [
        "def predict_test(model, data_loader):\n",
        "  preds = []\n",
        "  labels = []\n",
        "  with torch.no_grad():\n",
        "    for data, label in data_loader:\n",
        "      data = data.to(DEVICE)\n",
        "      label = label.to(DEVICE)\n",
        "      # 신경망에 이미지를 통과시켜 출력을 계산\n",
        "      outputs = model(data)\n",
        "      # 가장 높은 값(energy)를 갖는 분류(class)를 정답으로 선택\n",
        "      _, pred = torch.max(outputs, 1)\n",
        "      for i in pred:\n",
        "        preds.append(int(i))\n",
        "      for j in label:\n",
        "        labels.append(int(j))\n",
        "  return preds, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGW1zS9bA8Xx"
      },
      "source": [
        "# Transfer Learning with 모델 학습\n",
        "\n",
        "* Transfer Learning이 익숙하지 않으신 분들은 PyTorch에서 제공하는 https://9bow.github.io/PyTorch-tutorials-kr-0.3.1/beginner/transfer_learning_tutorial.html 을 참고하세요 :)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUcSsBx8QYO_",
        "outputId": "9fcf2dc7-7f78-4714-9e71-b1f0aada14cc"
      },
      "source": [
        "# Data Augmentation \n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        ### 데이터 전처리를 진행해 주세요 ###\n",
        "        transforms.Resize([256,256]),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(brightness=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
        "    \n",
        "    'val': transforms.Compose([\n",
        "        ### 데이터 전처리를 진행해 주세요 ###\n",
        "        transforms.Resize([256,256]),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])\n",
        "}\n",
        "\n",
        "train_dataset_resnet = ImageFolder(root='./splitted/train', transform = data_transforms['train'])\n",
        "val_dataset_resnet = ImageFolder(root='./splitted/val', transform = data_transforms['val'])\n",
        "\n",
        "train_loader_resnet = torch.utils.data.DataLoader(train_dataset_resnet, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "val_loader_resnet = torch.utils.data.DataLoader(val_dataset_resnet, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dHs4MzGBAx1"
      },
      "source": [
        "from torchvision import models\n",
        " \n",
        "resnet = models.resnet50(pretrained=True)   # resnet50 불러오기, pretrained = True로 학습된 파라미터 값들 불러오기\n",
        "num_ftrs = resnet.fc.in_features            # resnet50의 fully connected layer의 input 노드 수\n",
        "resnet.fc = nn.Linear(num_ftrs, 21)         # input 노드 수를 이용해 새로운 layer 추가\n",
        "resnet = resnet.to(DEVICE)                  # resnet 모델 DEVICE에 할당\n",
        " \n",
        "criterion = nn.CrossEntropyLoss()                                                           # CrossEntropyLoss 로 loss 계산\n",
        "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, resnet.parameters()), lr=0.001) # optimizer -> adam"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mZxaZDDBMw6"
      },
      "source": [
        "# Pretrained Model의 일부 layer freeze 하기\n",
        "ct = 0 \n",
        "for child in resnet.children():  \n",
        "    ct+= 1  \n",
        "    if ct < 7: \n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8f1GA7HIgu4"
      },
      "source": [
        "Fine Tuning을 진행해 주세요!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQEtXPzOBSSy"
      },
      "source": [
        "def train_resnet(model ,train_loader, val_loader, optimizer, num_epochs = 30):\n",
        "    ### finetuning 함수를 만들어 주세요 ### \n",
        "    ### (위의 train_baseline 함수 참고) ###\n",
        "    best_acc = 0.0  \n",
        "    best_model_wts = copy.deepcopy(model.state_dict()) \n",
        " \n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        since = time.time()  \n",
        "        train(model, train_loader, optimizer)\n",
        "        train_loss, train_acc = evaluate(model, train_loader)\n",
        "        val_loss, val_acc = evaluate(model, val_loader)\n",
        "        \n",
        "        if val_acc>best_acc: \n",
        "            best_acc = val_acc \n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        time_elapsed = time.time() - since \n",
        "        print('-------------- epoch {} ----------------'.format(epoch))\n",
        "        print('train Loss: {:.4f}, Accuracy: {:.2f}%'.format(train_loss, train_acc))   \n",
        "        print('val Loss: {:.4f}, Accuracy: {:.2f}%'.format(val_loss, val_acc))\n",
        "        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) \n",
        "\n",
        "\n",
        "    model.load_state_dict(best_model_wts)  \n",
        "    return model"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgC-YEr85UzR",
        "outputId": "263982bb-1b16-4959-a1b4-cfc58ce9e71e"
      },
      "source": [
        "import copy\n",
        "import time\n",
        "\n",
        "resnet_train = train_resnet(resnet, train_loader_resnet, val_loader_resnet, optimizer_ft)  # resnet transfer learning 진행"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------- epoch 1 ----------------\n",
            "train Loss: 0.8285, Accuracy: 38.74%\n",
            "val Loss: 1.2713, Accuracy: 39.47%\n",
            "Completed in 2m 20s\n",
            "-------------- epoch 2 ----------------\n",
            "train Loss: 0.0317, Accuracy: 63.52%\n",
            "val Loss: 0.0414, Accuracy: 61.42%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 3 ----------------\n",
            "train Loss: 0.0136, Accuracy: 77.48%\n",
            "val Loss: 0.0226, Accuracy: 74.18%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 4 ----------------\n",
            "train Loss: 0.0179, Accuracy: 69.32%\n",
            "val Loss: 0.0312, Accuracy: 68.25%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 5 ----------------\n",
            "train Loss: 0.0122, Accuracy: 77.29%\n",
            "val Loss: 0.0182, Accuracy: 74.78%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 6 ----------------\n",
            "train Loss: 0.0079, Accuracy: 82.40%\n",
            "val Loss: 0.0190, Accuracy: 71.51%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 7 ----------------\n",
            "train Loss: 0.0111, Accuracy: 80.14%\n",
            "val Loss: 0.0222, Accuracy: 70.62%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 8 ----------------\n",
            "train Loss: 0.0182, Accuracy: 70.89%\n",
            "val Loss: 0.0289, Accuracy: 64.99%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 9 ----------------\n",
            "train Loss: 0.0053, Accuracy: 89.18%\n",
            "val Loss: 0.0132, Accuracy: 76.26%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 10 ----------------\n",
            "train Loss: 0.0027, Accuracy: 94.59%\n",
            "val Loss: 0.0118, Accuracy: 79.23%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 11 ----------------\n",
            "train Loss: 0.0039, Accuracy: 90.56%\n",
            "val Loss: 0.0166, Accuracy: 80.42%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 12 ----------------\n",
            "train Loss: 0.0042, Accuracy: 90.36%\n",
            "val Loss: 0.0148, Accuracy: 78.34%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 13 ----------------\n",
            "train Loss: 0.0069, Accuracy: 87.02%\n",
            "val Loss: 0.0192, Accuracy: 76.26%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 14 ----------------\n",
            "train Loss: 0.0024, Accuracy: 94.49%\n",
            "val Loss: 0.0180, Accuracy: 77.45%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 15 ----------------\n",
            "train Loss: 0.0023, Accuracy: 95.08%\n",
            "val Loss: 0.0153, Accuracy: 78.64%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 16 ----------------\n",
            "train Loss: 0.0015, Accuracy: 96.85%\n",
            "val Loss: 0.0152, Accuracy: 78.64%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 17 ----------------\n",
            "train Loss: 0.0055, Accuracy: 90.46%\n",
            "val Loss: 0.0203, Accuracy: 75.96%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 18 ----------------\n",
            "train Loss: 0.0033, Accuracy: 93.81%\n",
            "val Loss: 0.0177, Accuracy: 77.45%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 19 ----------------\n",
            "train Loss: 0.0015, Accuracy: 96.85%\n",
            "val Loss: 0.0155, Accuracy: 79.82%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 20 ----------------\n",
            "train Loss: 0.0035, Accuracy: 91.84%\n",
            "val Loss: 0.0265, Accuracy: 70.62%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 21 ----------------\n",
            "train Loss: 0.0026, Accuracy: 94.10%\n",
            "val Loss: 0.0198, Accuracy: 75.67%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 22 ----------------\n",
            "train Loss: 0.0018, Accuracy: 96.56%\n",
            "val Loss: 0.0162, Accuracy: 78.64%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 23 ----------------\n",
            "train Loss: 0.0089, Accuracy: 84.76%\n",
            "val Loss: 0.0345, Accuracy: 69.44%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 24 ----------------\n",
            "train Loss: 0.0070, Accuracy: 86.43%\n",
            "val Loss: 0.0199, Accuracy: 72.40%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 25 ----------------\n",
            "train Loss: 0.0022, Accuracy: 95.58%\n",
            "val Loss: 0.0136, Accuracy: 82.20%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 26 ----------------\n",
            "train Loss: 0.0068, Accuracy: 88.10%\n",
            "val Loss: 0.0297, Accuracy: 69.14%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 27 ----------------\n",
            "train Loss: 0.0028, Accuracy: 95.28%\n",
            "val Loss: 0.0150, Accuracy: 80.71%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 28 ----------------\n",
            "train Loss: 0.0011, Accuracy: 97.54%\n",
            "val Loss: 0.0172, Accuracy: 80.42%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 29 ----------------\n",
            "train Loss: 0.0037, Accuracy: 92.72%\n",
            "val Loss: 0.0242, Accuracy: 76.56%\n",
            "Completed in 0m 31s\n",
            "-------------- epoch 30 ----------------\n",
            "train Loss: 0.0010, Accuracy: 98.33%\n",
            "val Loss: 0.0162, Accuracy: 79.53%\n",
            "Completed in 0m 31s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2Eax65TCHgM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e23b7ef2-c658-4ecd-8ffa-0fa071ab6d88"
      },
      "source": [
        "# Classification 하기\n",
        "transform_res = transforms.Compose([\n",
        "        ### 데이터 전처리 ###\n",
        "        transforms.Resize([256,256]),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "]) \n",
        "test_res = ImageFolder(root='./splitted/test',transform=transform_res)  \n",
        "test_loader_res = torch.utils.data.DataLoader(test_res, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "048O7OR5ZACO"
      },
      "source": [
        "def predict_test(model, data_loader):\n",
        "  preds = []\n",
        "  labels = []\n",
        "  with torch.no_grad():\n",
        "    for data, label in data_loader:\n",
        "      data = data.to(DEVICE)\n",
        "      label = label.to(DEVICE)\n",
        "      # 신경망에 이미지를 통과시켜 출력을 계산\n",
        "      outputs = model(data)\n",
        "      # 가장 높은 값(energy)를 갖는 분류(class)를 정답으로 선택\n",
        "      _, pred = torch.max(outputs, 1)\n",
        "      for i in pred:\n",
        "        preds.append(int(i))\n",
        "      for j in label:\n",
        "        labels.append(int(j))\n",
        "  return preds, labels"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IO4E5_FX-fQ"
      },
      "source": [
        "# 모델 평가\n",
        "\n",
        "모델 평가를 진행할 때 accuracy, precision, recall f1-score 등 다양한 평가지표를 가지고 진행해 주세요 ~!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26zqjZd7a3Wt"
      },
      "source": [
        "### 베이스라인 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt-93HBNh1In",
        "outputId": "e5e4ed87-ac3c-45da-ca36-29b696975d99"
      },
      "source": [
        "predictions, labels = predict_test(base, test_loader_base)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfqlQcnEaWXW",
        "outputId": "f1515b49-7e33-41e6-d7d4-a0873bdae700"
      },
      "source": [
        "print(predictions[:10])\n",
        "print(labels[:10])"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 6, 0, 5, 6, 6, 2, 6, 6, 5]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nl-z8_TZ0Ij",
        "outputId": "d8d37c45-9082-4fb2-9b46-4e3791feb634"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "round(accuracy_score(labels, predictions)*100,1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39.8"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdjExP2ZaxGJ"
      },
      "source": [
        "### Transfer Learning 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn5bE5fAZDfX",
        "outputId": "cbb7a6b9-87e5-4fc2-bee3-eafadbb720e0"
      },
      "source": [
        "preds, labels = predict_test(resnet, test_loader_res)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M31J7ZBiarBz",
        "outputId": "5dcfafc9-d62d-4596-fbc0-2ed88e4474e0"
      },
      "source": [
        "print(preds[:10])\n",
        "print(labels[:10])"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 2, 0, 0, 4, 4]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KVbE2Noi_Lv"
      },
      "source": [
        "##### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIiu6DA4m6ii",
        "outputId": "39a52762-a19d-4455-add0-95baae6d4109"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(labels, preds)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[53,  0,  4,  2,  3,  0,  3],\n",
              "       [ 6, 27,  3,  1,  1,  0,  3],\n",
              "       [ 0,  0, 45,  1,  0,  0,  1],\n",
              "       [ 1,  1,  0, 23,  0,  0,  1],\n",
              "       [ 4,  1,  5,  0, 17,  0,  3],\n",
              "       [ 1,  0,  1,  0,  0, 46,  1],\n",
              "       [ 3,  3,  4,  0,  1,  2, 66]])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USirC3h_iZcf",
        "outputId": "119cb174-8646-4061-e869-dc73d1f1f0e6"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = ['0','1','2','3','4','5','6']\n",
        "print(classification_report(labels, preds, target_names=target_names))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.82      0.80        65\n",
            "           1       0.84      0.66      0.74        41\n",
            "           2       0.73      0.96      0.83        47\n",
            "           3       0.85      0.88      0.87        26\n",
            "           4       0.77      0.57      0.65        30\n",
            "           5       0.96      0.94      0.95        49\n",
            "           6       0.85      0.84      0.84        79\n",
            "\n",
            "    accuracy                           0.82       337\n",
            "   macro avg       0.83      0.81      0.81       337\n",
            "weighted avg       0.83      0.82      0.82       337\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyVYQes3o8t7",
        "outputId": "90fd67bf-c008-42bd-eb26-9aeb3f96c7f4"
      },
      "source": [
        "f1_score(labels, preds, average=None)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.79699248, 0.73972603, 0.82568807, 0.86792453, 0.65384615,\n",
              "       0.94845361, 0.84076433])"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GygVwITooiCh"
      },
      "source": [
        "##### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3jHcdgzoiLK",
        "outputId": "4e61798d-a018-4c42-b4a6-e4e608cdcb53"
      },
      "source": [
        "round(accuracy_score(labels, preds)*100,1)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82.2"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    }
  ]
}
